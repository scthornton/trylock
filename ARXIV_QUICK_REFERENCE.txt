=== TRYLOCK arXiv Submission - Quick Reference ===

TITLE:
TRYLOCK: Defense-in-Depth Against LLM Jailbreaks via Layered Preference and Representation Engineering

AUTHORS:
Scott Thornton

AFFILIATIONS:
Independent Researcher

CONTACT:
scott@perfecxion.ai

PRIMARY CATEGORY:
cs.CR (Cryptography and Security)

CROSS-LIST CATEGORIES:
cs.LG (Machine Learning)
cs.AI (Artificial Intelligence)
cs.CL (Computation and Language)

ABSTRACT (1,603 characters):
Large Language Models (LLMs) remain vulnerable to jailbreak attacks that bypass safety alignment through prompt manipulation, multi-turn social engineering, and obfuscation. Existing defenses operate at a single layer—either modifying weights during training or adding guardrails at inference—leaving gaps that sophisticated attacks exploit. We present TRYLOCK (Adaptive Ensemble Guard with Integrated Steering), a defense-in-depth architecture combining three mechanisms: (1) Direct Preference Optimization (DPO) to train the model to recognize and refuse jailbreaks, (2) Representation Engineering (RepE) to steer activations away from attack-compliant directions at inference, and (3) a lightweight sidecar classifier enabling adaptive steering strength based on threat assessment.

We train TRYLOCK on 14,137 multi-turn attack trajectories plus 2,118 benign hard negatives, deriving 2,939 preference pairs (2,640 for training, 299 for evaluation). On this benchmark spanning five attack families, the two-layer configuration (DPO + RepE) reduces Attack Success Rate from 46.5% to 8.0%—an 82.8% relative reduction—while the three-layer configuration adds adaptive threat classification. Ablations show each layer provides independent protection: DPO yields 14.4% ASR reduction, RepE adds ~80% over DPO alone. However, RepE requires careful implementation; 8-bit quantization degraded performance to 84.7% ASR, suggesting full-precision deployment is critical. We release all components—adapters, steering vectors, classifier, and datasets—for reproducible research on layered LLM safety.

COMMENTS:
Code and datasets available at https://github.com/scthornton/trylock

LICENSE:
CC BY-NC-SA 4.0

KEYWORDS:
LLM Security, Jailbreak Defense, Representation Engineering, Direct Preference Optimization, Adversarial Machine Learning, AI Safety

SUBMISSION URL:
https://arxiv.org/submit

=== END QUICK REFERENCE ===
